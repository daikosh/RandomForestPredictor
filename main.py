import os
import datetime
import base64

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

from sklearn.model_selection import train_test_split

# è©•ä¾¡æŒ‡æ¨™
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score

# Random Forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
TODAY = datetime.datetime.today().strftime("%Y%m%d_")


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Random Forest Predictor ver.1.0",
    page_icon="ğŸŒ´",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Streamlitã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚„ãƒ•ãƒƒã‚¿ãƒ¼ã‚’éš ã™
hide_streamlit_style = """
    <style>
        MainMenu {visibility: hidden;}
        footer {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)


# ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹
class RandomForestPredictor(object):
    def __init__(self):
        pass

    def show_image(self, imgpath):
        """ç”»åƒã‚’è¡¨ç¤º"""
        if os.path.exists(imgpath):
            image = Image.open(imgpath)
            st.image(image, use_column_width="auto")

    def get_table_download_link(self, df):
        """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’å–å¾—"""
        nowtime = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        csv = df.to_csv(index=True)
        b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here
        href = f'<a href="data:file/csv;base64,{b64}" download="{nowtime}.csv">Download</a>'
        return href

    def preprocess(self, df_uploaded):
        """å‰å‡¦ç†"""

        # ä¸è¦ãªç‰¹å¾´é‡ã®æ¶ˆå»
        drop_features = [
            'Job Code', 'Project Name', 'Tag Number',\
            'Operation Frequency', 'HP', 'HP\nTotal',\
            'Small Nozzle Size', 'Remarks', 'h', 'h1',\
            'Propeller Diameter', 'Large Nozzle Size',\
            'Content Details', 'Content Kind',\
            'Floating \nRoof', 'Vendor', 'kW\nTotal',\
            'Viscosity', 'Operating Temperature', 'Tank ID',\
            'TEST DATA', 'Power Rating', 'kW', 'Tank Height'
            ]
        df = df_uploaded.drop(drop_features, axis=1)

        # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒ€ãƒŸãƒ¼åŒ– + NC_per_Qtyåˆ—ã®ä½œæˆ
        fulldata = [df]
        for dataset in fulldata:
            dataset['Tank Type_CRT'] = dataset['Tank Type'].map(
                {'CRT': 1, 'FRT': 0, 'IFRT': 0, 'OTT': 0, 'DRT': 0, 'IFRT\n(DRT)': 0}
            )
            dataset['Tank Type_FRT'] = dataset['Tank Type'].map(
                    {'CRT': 0, 'FRT': 1, 'IFRT': 1, 'OTT': 1, 'DRT': 1, 'IFRT\n(DRT)': 1}
                )
            dataset['Content Type_1'] = dataset['Content Type'].map({1: 1, 2: 0, 3: 0})
            dataset['Content Type_2'] = dataset['Content Type'].map({1: 0, 2: 1, 3: 0})
            dataset['Purpose_1'] = dataset['Purpose'].map({1: 1, 2: 0, 3: 0})
            dataset['Purpose_2'] = dataset['Purpose'].map({1: 0, 2: 1, 3: 0})
            dataset['NC_per_Qty'] = dataset['Nominal Capacity']/dataset['Qty']

        # ä¸è¦ãªç‰¹å¾´é‡ã®æ¶ˆå»
        df.drop(['Tank Type', 'Content Type', 'Purpose', 'Vendor Number', 'Nominal Capacity', 'Qty'], axis=1, inplace=True)

        return df

    def predict(self, df, modelpath):
        """äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§y_predã‚’äºˆæ¸¬ã™ã‚‹"""

        # å­¦ç¿’ã•ã‚ŒãŸäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        loaded_model = pickle.load(open(modelpath, 'rb'))

        # y_predã‚’äºˆæ¸¬
        x = df
        y_pred = loaded_model.predict(x)

        return y_pred

    def create_df_results(self, df, y_pred):
        """df_resultsã®ä½œæˆ"""

        # df_resultsã®ä½œæˆ
        x = df
        df_results = pd.DataFrame(y_pred.tolist(), index=x.index, columns=['kW pred'])

        # y_predã‚’å¹³å‡å€¤ã§åŒºåˆ‡ã£ã¦ã€Power Ratingã«å¤‰æ›
        bins_ave = [-99, (2.2+3.7)/2, (3.7+5.5)/2, (5.5+7.5)/2, (7.5+11)/2, (11+15)/2,
                    (15+18)/2, (18+22)/2, (22+30)/2, (30+37)/2, (37+45)/2, (45+55)/2, 99]
        labels_unit_power = [2.2, 3.7, 5.5, 7.5, 11, 15, 18, 22, 30, 37, 45, 55]
        list_kw_to_power_rating = {2.2:1, 3.7:2, 5.5:3, 7.5:4, 11:5, 15:6, 18:7, 22:8, 30:9, 37:10, 45:11, 55:12}
        df_results['kW pred (round)'] = pd.cut(df_results['kW pred'], bins=bins_ave, labels=labels_unit_power).values
        df_results['Power Rating pred'] = df_results['kW pred (round)'].apply(list_kw_to_power_rating.__getitem__)

        return df_results

    def draw_pairplot(self, df):
        fig = plt.figure()
        sns.pairplot(df)
        st.pyplot(fig)

    def draw_heatmap(self, df, annot):
        fig = plt.figure()
        sns.heatmap(df, vmin=-1, vmax=1, center=0, cmap='bwr', annot=annot)
        st.pyplot(fig)

    def open(self):
        """ãƒšãƒ¼ã‚¸ã®è¡¨ç¤º"""

        # ã‚¿ã‚¤ãƒˆãƒ«ã®è¡¨ç¤º
        st.title("Random Forest Predictor  ver.1.0")
        st.write("æ©Ÿæ¢°å­¦ç¿’ (æ•™å¸«ã‚ã‚Šå­¦ç¿’) ã‚’æ‰‹è»½ã«ä½“é¨“ã§ãã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚")
        st.write("â‘ ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã€â‘¡ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã€â‘¢äºˆæ¸¬ (å›å¸°ã€åˆ†é¡) ãŒã§ãã¾ã™ã€‚")
        st.write("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã”ä½¿ç”¨ãã ã•ã„ã€‚")
        st.write("â€» é‡çš„ãƒ‡ãƒ¼ã‚¿ã«ã®ã¿å¯¾å¿œã—ã¦ãŠã‚Šã¾ã™ã€‚ä¾‹) [Red Wine Quality (Kaggle)](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)")
        
        st.sidebar.header("0. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º
        uploaded_file = st.sidebar.file_uploader("Upload a csv file / csvãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if uploaded_file is not None:
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            df_uploaded = pd.read_csv(uploaded_file)

            # ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
            st.subheader("1. ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªãƒ»å¯è¦–åŒ–")
            with st.expander("Uploaded Data"):
                st.dataframe(df_uploaded)
                st.markdown(df_uploaded.shape)

            with st.expander("ç›®çš„å¤‰æ•°ã®é¸æŠ"):
                target = st.selectbox(
                    'ç›®çš„å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„',
                    df_uploaded.columns
                )

            with st.expander("åŸºæœ¬çµ±è¨ˆé‡"):
                st.dataframe(df_uploaded.describe())

            with st.expander("æ¬ æå€¤"):
                st.dataframe(df_uploaded.isnull().sum())

            with st.expander("ç›¸é–¢ä¿‚æ•°"):
                st.dataframe(df_uploaded.corr())
                st.subheader("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
                heatmap_annot = st.checkbox('ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«æ•°å€¤ã‚’è¡¨ç¤º')
                self.draw_heatmap(df_uploaded.corr(), heatmap_annot)
                self.draw_pairplot(df_uploaded)
                st.subheader("å„èª¬æ˜å¤‰æ•° x ç›®çš„å¤‰æ•° ã®æ•£å¸ƒå›³")
                checked_variable = st.selectbox(
                    'èª¬æ˜å¤‰æ•°ã‚’1ã¤é¸æŠã—ã¦ãã ã•ã„:',
                    df_uploaded.select_dtypes(include='number').columns
                )
                fig, ax = plt.subplots(figsize=(5, 3))
                ax.scatter(x=df_uploaded[checked_variable], y=df_uploaded[target])
                plt.xlabel(checked_variable)
                plt.ylabel(target)
                st.pyplot(fig)

            st.subheader("2. ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†")
            st.sidebar.header("3. å­¦ç¿’ (ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚°)")
            # èª¬æ˜å¤‰æ•°ã¨ç›®çš„å¤‰æ•°ã®è¨­å®š
            x = df_uploaded.drop(target,axis=1)
            y = df_uploaded[target]

            with st.expander("æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ"):
                #æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’è¨­å®š
                TEST_SIZE  = st.slider('æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆã‚’è¨­å®š', 0.1, 0.5)

            # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            x_train, x_test, y_train, y_test = train_test_split(
                x,
                y,
                test_size=TEST_SIZE,
                random_state=42,
                )

            with st.expander("ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š"):
                n_estimators = st.slider("n_estimators", 1, 1000)
                max_depth = st.slider("max_depth", 1, 100)
                criterion = st.radio("criterion", ["mse", "mae", "poisson"])
                bootstrap = st.radio("bootstrap", ["True", "False"])

            if st.button('äºˆæ¸¬é–‹å§‹'):
                #ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
                rf_reg = RandomForestRegressor(
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    criterion=criterion,
                    bootstrap=bootstrap,
                )
                rf_reg.fit(x_train, y_train)

                #äºˆæ¸¬
                y_pred = rf_reg.predict(x_test)

                #ç²¾åº¦è©•ä¾¡
                scores = pd.DataFrame({
                    "R2": r2_score(y_test, y_pred),
                    "MAE": mean_absolute_error(y_test, y_pred),
                    "MSE": mean_squared_error(y_test, y_pred),
                    "RMSE": np.sqrt(mean_squared_error(y_test, y_pred))},index=["scores"])

                st.sidebar.header("ç²¾åº¦è©•ä¾¡ã‚’è¡¨ç¤º")
                st.dataframe(scores)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆ
        else:
            # è­¦å‘Šã®è¡¨ç¤º
            st.warning("Please upload a csv file.")

        # ãƒ•ãƒƒã‚¿ãƒ¼ã®è¡¨ç¤º
        st.write("Copyright Â© daikosh 2022. All Rights Reserved.")
        st.sidebar.write("Copyright Â© daikosh 2022. All Rights Reserved.")


if __name__ == "__main__":
    # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ç”Ÿæˆ
    predictor = RandomForestPredictor()
    predictor.open()
